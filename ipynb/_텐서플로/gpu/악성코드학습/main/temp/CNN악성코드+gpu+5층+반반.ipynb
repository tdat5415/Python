{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001 #0.001\n",
    "training_epochs = 45 #15\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#인코딩중요\n",
    "#라벨만들기\n",
    "with open('./trainSet.csv', 'r', encoding='UTF-8-sig') as raw:\n",
    "    lines = raw.readlines()\n",
    "data = list(csv.reader(lines))\n",
    "data = sorted(data, key=lambda x: x[0])\n",
    "\n",
    "#이름빼기\n",
    "_Y = [y[1] for y in data]\n",
    "\n",
    "_Y = np.array(_Y)\n",
    "_Y = _Y.astype(float) # shape(-1)\n",
    "_Y = [[1-y, y] for y in _Y] # shape(-1, 2)\n",
    "\n",
    "\n",
    "#데이터만들기\n",
    "with open('./features1024.csv', 'r', encoding='UTF-8-sig') as raw:\n",
    "    lines = raw.readlines()\n",
    "data = list(csv.reader(lines))\n",
    "data = sorted(data, key=lambda x: x[0])\n",
    "\n",
    "#이름빼기\n",
    "_X = [x[1:] for x in data]\n",
    "\n",
    "_X = np.array(_X)\n",
    "_X = _X.astype(float) # shape(-1, 1024)\n",
    "\n",
    "\n",
    "all_set = tuple(zip(_X, _Y)) # shape(10000, 2, ~)\n",
    "M_all_set = [all_set[i] for i in range(len(all_set)) if all_set[i][1][1] == 1] # 7000\n",
    "N_all_set = [all_set[i] for i in range(len(all_set)) if all_set[i][1][0] == 1] # 3000\n",
    "np.random.shuffle(M_all_set)\n",
    "np.random.shuffle(N_all_set)\n",
    "\n",
    "# 악성,정상 개수 맞추기\n",
    "if len(M_all_set) > len(N_all_set):\n",
    "    M_all_set = M_all_set[:len(N_all_set)]\n",
    "else:\n",
    "    N_all_set = N_all_set[:len(M_all_set)]\n",
    "\n",
    "all_set = M_all_set + N_all_set\n",
    "np.random.shuffle(all_set) # 6000\n",
    "\n",
    "train_set = all_set[len(all_set)//5:] # 4800\n",
    "test_set = all_set[:len(all_set)//5] # 1200\n",
    "\n",
    "train_X = np.array([X for X,Y in train_set])\n",
    "train_Y = np.array([Y for X,Y in train_set])\n",
    "test_X = np.array([X for X,Y in test_set])\n",
    "test_Y = np.array([Y for X,Y in test_set])\n",
    "\n",
    "\n",
    "M_test_X = [X for X,Y in test_set if Y[1] == 1] # label의 악성이면\n",
    "M_test_Y = [Y for X,Y in test_set if Y[1] == 1] # label의 악성이면\n",
    "\n",
    "N_test_X = [X for X,Y in test_set if Y[0] == 1] # label의 정상이면\n",
    "N_test_Y = [Y for X,Y in test_set if Y[0] == 1] # label의 정상이면\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-9012311ed238>:9: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-5-9012311ed238>:49: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = 5\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    X = tf.placeholder(tf.float32, [None, 1024])\n",
    "    X_img = tf.reshape(X, [-1, 32, 32, 1]) # img 28x28x1 (black/white)\n",
    "    Y = tf.placeholder(tf.float32, [None, 2])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    X_img = tf.nn.dropout(X_img, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "    # L1 ImgIn shape=(?, 32, 32, 1)\n",
    "    W1 = tf.Variable(tf.random_normal([s, s, 1, 32], stddev=0.01))\n",
    "    L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding='SAME')\n",
    "    L1 = tf.nn.relu(L1)\n",
    "    L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "    #    Conv    -> (?, 32, 32, 32)\n",
    "    #    Pool    -> (?, 16, 16, 32)\n",
    "\n",
    "\n",
    "    # L2 ImgIn shape=(?, 16, 16, 32)\n",
    "    W2 = tf.Variable(tf.random_normal([s, s, 32, 64], stddev=0.01))\n",
    "    L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "    #    Conv    -> (?, 16, 16, 64)\n",
    "    #    Pool    -> (?, 8, 8, 64)\n",
    "\n",
    "\n",
    "    # L3 ImgIn shape=(?, 8, 8, 64)\n",
    "    W3 = tf.Variable(tf.random_normal([s, s, 64, 128], stddev=0.01))\n",
    "    L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1], padding='SAME')\n",
    "    L3 = tf.nn.relu(L3)\n",
    "    L3 = tf.nn.max_pool(L3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    L3 = tf.reshape(L3, [-1, 4 * 4 * 128])\n",
    "    L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "    #    Conv    -> (?, 8, 8, 128)\n",
    "    #    Pool    -> (?, 4, 4, 128)\n",
    "    #    Pool    -> (?, 2048)\n",
    "    \n",
    "\n",
    "    W4 = tf.get_variable('W4', shape=[4*4*128, 2], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.Variable(tf.random_normal([2]))\n",
    "    hypothesis = tf.matmul(L3, W4) + b\n",
    "\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0001 cost =  0.697726358\n",
      "Epoch :  0002 cost =  0.656782432\n",
      "Epoch :  0003 cost =  0.644641911\n",
      "Epoch :  0004 cost =  0.630973715\n",
      "Epoch :  0005 cost =  0.619731975\n",
      "Epoch :  0006 cost =  0.612604325\n",
      "Epoch :  0007 cost =  0.602911610\n",
      "Epoch :  0008 cost =  0.600419056\n",
      "Epoch :  0009 cost =  0.597762300\n",
      "Epoch :  0010 cost =  0.595092575\n",
      "Epoch :  0011 cost =  0.585719456\n",
      "Epoch :  0012 cost =  0.580833750\n",
      "Epoch :  0013 cost =  0.574755672\n",
      "Epoch :  0014 cost =  0.572459965\n",
      "Epoch :  0015 cost =  0.567043590\n",
      "Epoch :  0016 cost =  0.560299223\n",
      "Epoch :  0017 cost =  0.551397273\n",
      "Epoch :  0018 cost =  0.551827832\n",
      "Epoch :  0019 cost =  0.545357560\n",
      "Epoch :  0020 cost =  0.538963630\n",
      "Epoch :  0021 cost =  0.535936861\n",
      "Epoch :  0022 cost =  0.525861969\n",
      "Epoch :  0023 cost =  0.519404899\n",
      "Epoch :  0024 cost =  0.507670943\n",
      "Epoch :  0025 cost =  0.499120821\n",
      "Epoch :  0026 cost =  0.499457578\n",
      "Epoch :  0027 cost =  0.492459379\n",
      "Epoch :  0028 cost =  0.482101799\n",
      "Epoch :  0029 cost =  0.474387554\n",
      "Epoch :  0030 cost =  0.471906111\n",
      "Epoch :  0031 cost =  0.458503289\n",
      "Epoch :  0032 cost =  0.453805044\n",
      "Epoch :  0033 cost =  0.450828128\n",
      "Epoch :  0034 cost =  0.442540866\n",
      "Epoch :  0035 cost =  0.446662805\n",
      "Epoch :  0036 cost =  0.442712707\n",
      "Epoch :  0037 cost =  0.434369958\n",
      "Epoch :  0038 cost =  0.419739347\n",
      "Epoch :  0039 cost =  0.423018269\n",
      "Epoch :  0040 cost =  0.417758421\n",
      "Epoch :  0041 cost =  0.406629938\n",
      "Epoch :  0042 cost =  0.404178303\n",
      "Epoch :  0043 cost =  0.407086102\n",
      "Epoch :  0044 cost =  0.399250956\n",
      "Epoch :  0045 cost =  0.393739578\n",
      "Epoch :  0046 cost =  0.395027904\n",
      "Epoch :  0047 cost =  0.387584835\n",
      "Epoch :  0048 cost =  0.385061409\n",
      "Epoch :  0049 cost =  0.386167144\n",
      "Epoch :  0050 cost =  0.367027357\n",
      "Epoch :  0051 cost =  0.371929975\n",
      "Epoch :  0052 cost =  0.375044384\n",
      "Epoch :  0053 cost =  0.366516846\n",
      "Epoch :  0054 cost =  0.369418414\n",
      "Epoch :  0055 cost =  0.368940519\n",
      "Epoch :  0056 cost =  0.356082802\n",
      "Epoch :  0057 cost =  0.352142964\n",
      "Epoch :  0058 cost =  0.354175834\n",
      "Epoch :  0059 cost =  0.353958941\n",
      "Epoch :  0060 cost =  0.346735805\n",
      "Epoch :  0061 cost =  0.344267255\n",
      "Epoch :  0062 cost =  0.331255969\n",
      "Epoch :  0063 cost =  0.342334603\n",
      "Epoch :  0064 cost =  0.333736336\n",
      "Epoch :  0065 cost =  0.330203438\n",
      "Epoch :  0066 cost =  0.322750853\n",
      "Epoch :  0067 cost =  0.331171551\n",
      "Epoch :  0068 cost =  0.322438864\n",
      "Epoch :  0069 cost =  0.327091017\n",
      "Epoch :  0070 cost =  0.315465041\n",
      "Epoch :  0071 cost =  0.307557639\n",
      "Epoch :  0072 cost =  0.310628235\n",
      "Epoch :  0073 cost =  0.297440941\n",
      "Epoch :  0074 cost =  0.308678863\n",
      "Epoch :  0075 cost =  0.304103549\n",
      "Epoch :  0076 cost =  0.290818690\n",
      "Epoch :  0077 cost =  0.298094683\n",
      "Epoch :  0078 cost =  0.298963568\n",
      "Epoch :  0079 cost =  0.288671557\n",
      "Epoch :  0080 cost =  0.301975527\n",
      "Epoch :  0081 cost =  0.297963760\n",
      "Epoch :  0082 cost =  0.294789982\n",
      "Epoch :  0083 cost =  0.286675209\n",
      "Epoch :  0084 cost =  0.284517469\n",
      "Epoch :  0085 cost =  0.282587383\n",
      "Epoch :  0086 cost =  0.281276910\n",
      "Epoch :  0087 cost =  0.283291938\n",
      "Epoch :  0088 cost =  0.276442937\n",
      "Epoch :  0089 cost =  0.275406997\n",
      "Epoch :  0090 cost =  0.275507662\n",
      "Epoch :  0091 cost =  0.265491664\n",
      "Epoch :  0092 cost =  0.258618280\n",
      "Epoch :  0093 cost =  0.269497248\n",
      "Epoch :  0094 cost =  0.266231763\n",
      "Epoch :  0095 cost =  0.263383895\n",
      "Epoch :  0096 cost =  0.267687317\n",
      "Epoch :  0097 cost =  0.262180010\n",
      "Epoch :  0098 cost =  0.262113135\n",
      "Epoch :  0099 cost =  0.259162339\n",
      "Epoch :  0100 cost =  0.260541073\n",
      "Epoch :  0101 cost =  0.252671427\n",
      "Epoch :  0102 cost =  0.253081306\n",
      "Epoch :  0103 cost =  0.255550082\n",
      "Epoch :  0104 cost =  0.244195983\n",
      "Epoch :  0105 cost =  0.248159522\n",
      "Epoch :  0106 cost =  0.247779631\n",
      "Epoch :  0107 cost =  0.238988919\n",
      "Epoch :  0108 cost =  0.252346010\n",
      "Epoch :  0109 cost =  0.249289795\n",
      "Epoch :  0110 cost =  0.239732637\n",
      "Epoch :  0111 cost =  0.241423103\n",
      "Epoch :  0112 cost =  0.245846617\n",
      "Epoch :  0113 cost =  0.247526453\n",
      "Epoch :  0114 cost =  0.237612456\n",
      "Epoch :  0115 cost =  0.226655527\n",
      "Epoch :  0116 cost =  0.238691533\n",
      "Epoch :  0117 cost =  0.222760817\n",
      "Epoch :  0118 cost =  0.241231067\n",
      "Epoch :  0119 cost =  0.239869476\n",
      "Epoch :  0120 cost =  0.224083949\n",
      "Epoch :  0121 cost =  0.219939397\n",
      "Epoch :  0122 cost =  0.226300449\n",
      "Epoch :  0123 cost =  0.219145225\n",
      "Epoch :  0124 cost =  0.224028124\n",
      "Epoch :  0125 cost =  0.214307645\n",
      "Epoch :  0126 cost =  0.227817403\n",
      "Epoch :  0127 cost =  0.222731709\n",
      "Epoch :  0128 cost =  0.222595244\n",
      "Epoch :  0129 cost =  0.221345263\n",
      "Epoch :  0130 cost =  0.211511378\n",
      "Epoch :  0131 cost =  0.208480337\n",
      "Epoch :  0132 cost =  0.211660892\n",
      "Epoch :  0133 cost =  0.205117514\n",
      "Epoch :  0134 cost =  0.226115278\n",
      "Epoch :  0135 cost =  0.219011310\n",
      "Epoch :  0136 cost =  0.214500405\n",
      "Epoch :  0137 cost =  0.214238701\n",
      "Epoch :  0138 cost =  0.227621159\n",
      "Epoch :  0139 cost =  0.205900944\n",
      "Epoch :  0140 cost =  0.210944990\n",
      "Epoch :  0141 cost =  0.199278192\n",
      "Epoch :  0142 cost =  0.197204316\n",
      "Epoch :  0143 cost =  0.202031957\n",
      "Epoch :  0144 cost =  0.206132873\n",
      "Epoch :  0145 cost =  0.198872731\n",
      "Epoch :  0146 cost =  0.201624892\n",
      "Epoch :  0147 cost =  0.203053260\n",
      "Epoch :  0148 cost =  0.197943325\n",
      "Epoch :  0149 cost =  0.205659982\n",
      "Epoch :  0150 cost =  0.189995428\n",
      "Epoch :  0151 cost =  0.185264388\n",
      "Epoch :  0152 cost =  0.192481116\n",
      "Epoch :  0153 cost =  0.194631359\n",
      "Epoch :  0154 cost =  0.193672416\n",
      "Epoch :  0155 cost =  0.191111921\n",
      "Epoch :  0156 cost =  0.194099650\n",
      "Epoch :  0157 cost =  0.179515814\n",
      "Epoch :  0158 cost =  0.188775093\n",
      "Epoch :  0159 cost =  0.189022274\n",
      "Epoch :  0160 cost =  0.190844565\n",
      "Epoch :  0161 cost =  0.182895980\n",
      "Epoch :  0162 cost =  0.185427743\n",
      "Epoch :  0163 cost =  0.193360596\n",
      "Epoch :  0164 cost =  0.187467756\n",
      "Epoch :  0165 cost =  0.193959386\n",
      "Epoch :  0166 cost =  0.173034851\n",
      "Epoch :  0167 cost =  0.190957376\n",
      "Epoch :  0168 cost =  0.186143614\n",
      "Epoch :  0169 cost =  0.181161438\n",
      "Epoch :  0170 cost =  0.176905072\n",
      "Epoch :  0171 cost =  0.174152447\n",
      "Epoch :  0172 cost =  0.177935049\n",
      "Epoch :  0173 cost =  0.171718786\n",
      "Epoch :  0174 cost =  0.188111266\n",
      "Epoch :  0175 cost =  0.181256601\n",
      "Epoch :  0176 cost =  0.181775546\n",
      "Epoch :  0177 cost =  0.177445240\n",
      "Epoch :  0178 cost =  0.171490863\n",
      "Epoch :  0179 cost =  0.182324670\n",
      "Epoch :  0180 cost =  0.182841656\n",
      "Epoch :  0181 cost =  0.174119885\n",
      "Epoch :  0182 cost =  0.175973829\n",
      "Epoch :  0183 cost =  0.180446353\n",
      "Epoch :  0184 cost =  0.168733663\n",
      "Epoch :  0185 cost =  0.179196988\n",
      "Epoch :  0186 cost =  0.168365470\n",
      "Epoch :  0187 cost =  0.174131516\n",
      "Epoch :  0188 cost =  0.163698960\n",
      "Epoch :  0189 cost =  0.173897187\n",
      "Epoch :  0190 cost =  0.184582026\n",
      "Epoch :  0191 cost =  0.177975602\n",
      "Epoch :  0192 cost =  0.167957135\n",
      "Epoch :  0193 cost =  0.170968895\n",
      "Epoch :  0194 cost =  0.175449710\n",
      "Epoch :  0195 cost =  0.170015320\n",
      "Epoch :  0196 cost =  0.169063573\n",
      "Epoch :  0197 cost =  0.163982560\n",
      "Epoch :  0198 cost =  0.174680995\n",
      "Epoch :  0199 cost =  0.170787707\n",
      "Epoch :  0200 cost =  0.175702227\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(len(train_X) / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = train_X[i*100:(i+1)*100], train_Y[i*100:(i+1)*100]\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        #feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        \n",
    "        avg_cost += c / total_batch #뭉치갯수로 나누기\n",
    "        time.sleep(0.03)\n",
    "        \n",
    "    print('Epoch : ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-67ffedb450f6>:2: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n",
      "Accuracy :  0.8808333\n",
      "정탐율 :  0.91399664\n",
      "오탐율 :  0.8484349\n",
      "Label: [1]\n",
      "Prediction: [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "feed_dict = {X: test_X, Y: test_Y, keep_prob: 1}\n",
    "print(\"Accuracy : \", accuracy.eval(session=sess, feed_dict=feed_dict))\n",
    "\n",
    "feed_dict = {X: M_test_X, Y: M_test_Y, keep_prob: 1}\n",
    "print(\"정탐율 : \", accuracy.eval(session=sess, feed_dict=feed_dict))\n",
    "\n",
    "feed_dict = {X: N_test_X, Y: N_test_Y, keep_prob: 1}\n",
    "print(\"오탐율 : \", accuracy.eval(session=sess, feed_dict=feed_dict))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "r = rd.randint(0, len(test_X) - 1)\n",
    "print('Label:', sess.run(tf.argmax(test_Y[r:r+1], 1)))\n",
    "\n",
    "feed_dict = {X: test_X[r:r+1], keep_prob: 1}\n",
    "print('Prediction:', sess.run(tf.argmax(hypothesis, 1), feed_dict=feed_dict))\n",
    "\n",
    "plt.imshow(test_X[r:r+1].reshape(32, 32), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
