{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-93fd7ea11b9e>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 400\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\___Anaconda\\envs\\forTF\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-39d716d97cd3>:24: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#X = tf.nn.dropout(X, keep_prob=keep_prob)\n",
    "\n",
    "#W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "#W1 = tf.get_variable('W1', shape=[784,100], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#b1 = tf.Variable(tf.random_normal([100]))\n",
    "#L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "#L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "#W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "#W2 = tf.get_variable('W2', shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#b2 = tf.Variable(tf.random_normal([256]))\n",
    "#L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "#L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "#W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "W3 = tf.get_variable('W3', shape=[784,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(X, W3) + b3\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0001 cost =  1.781276995\n",
      "Epoch :  0002 cost =  0.996627649\n",
      "Epoch :  0003 cost =  0.735292177\n",
      "Epoch :  0004 cost =  0.607614563\n",
      "Epoch :  0005 cost =  0.532203963\n",
      "Epoch :  0006 cost =  0.482341519\n",
      "Epoch :  0007 cost =  0.446955998\n",
      "Epoch :  0008 cost =  0.420713165\n",
      "Epoch :  0009 cost =  0.400598351\n",
      "Epoch :  0010 cost =  0.384738365\n",
      "Epoch :  0011 cost =  0.371930886\n",
      "Epoch :  0012 cost =  0.361418578\n",
      "Epoch :  0013 cost =  0.352651955\n",
      "Epoch :  0014 cost =  0.345238192\n",
      "Epoch :  0015 cost =  0.338858802\n",
      "Epoch :  0016 cost =  0.333446552\n",
      "Epoch :  0017 cost =  0.328588937\n",
      "Epoch :  0018 cost =  0.324270409\n",
      "Epoch :  0019 cost =  0.320471069\n",
      "Epoch :  0020 cost =  0.317006457\n",
      "Epoch :  0021 cost =  0.313864655\n",
      "Epoch :  0022 cost =  0.311049995\n",
      "Epoch :  0023 cost =  0.308358924\n",
      "Epoch :  0024 cost =  0.305983966\n",
      "Epoch :  0025 cost =  0.303779067\n",
      "Epoch :  0026 cost =  0.301725099\n",
      "Epoch :  0027 cost =  0.299819750\n",
      "Epoch :  0028 cost =  0.298033950\n",
      "Epoch :  0029 cost =  0.296263606\n",
      "Epoch :  0030 cost =  0.294738196\n",
      "Epoch :  0031 cost =  0.293238348\n",
      "Epoch :  0032 cost =  0.291778665\n",
      "Epoch :  0033 cost =  0.290424772\n",
      "Epoch :  0034 cost =  0.289197739\n",
      "Epoch :  0035 cost =  0.287967136\n",
      "Epoch :  0036 cost =  0.286798792\n",
      "Epoch :  0037 cost =  0.285684509\n",
      "Epoch :  0038 cost =  0.284694931\n",
      "Epoch :  0039 cost =  0.283649655\n",
      "Epoch :  0040 cost =  0.282611914\n",
      "Epoch :  0041 cost =  0.281703080\n",
      "Epoch :  0042 cost =  0.280774367\n",
      "Epoch :  0043 cost =  0.279934197\n",
      "Epoch :  0044 cost =  0.279084850\n",
      "Epoch :  0045 cost =  0.278352608\n",
      "Epoch :  0046 cost =  0.277495154\n",
      "Epoch :  0047 cost =  0.276777358\n",
      "Epoch :  0048 cost =  0.276059399\n",
      "Epoch :  0049 cost =  0.275343617\n",
      "Epoch :  0050 cost =  0.274674561\n",
      "Epoch :  0051 cost =  0.273973560\n",
      "Epoch :  0052 cost =  0.273392911\n",
      "Epoch :  0053 cost =  0.272674059\n",
      "Epoch :  0054 cost =  0.272221906\n",
      "Epoch :  0055 cost =  0.271555639\n",
      "Epoch :  0056 cost =  0.271004987\n",
      "Epoch :  0057 cost =  0.270445590\n",
      "Epoch :  0058 cost =  0.269884057\n",
      "Epoch :  0059 cost =  0.269342424\n",
      "Epoch :  0060 cost =  0.268803555\n",
      "Epoch :  0061 cost =  0.268288182\n",
      "Epoch :  0062 cost =  0.267848139\n",
      "Epoch :  0063 cost =  0.267373205\n",
      "Epoch :  0064 cost =  0.266884432\n",
      "Epoch :  0065 cost =  0.266451260\n",
      "Epoch :  0066 cost =  0.265970329\n",
      "Epoch :  0067 cost =  0.265567342\n",
      "Epoch :  0068 cost =  0.265081243\n",
      "Epoch :  0069 cost =  0.264705068\n",
      "Epoch :  0070 cost =  0.264272124\n",
      "Epoch :  0071 cost =  0.263890267\n",
      "Epoch :  0072 cost =  0.263479654\n",
      "Epoch :  0073 cost =  0.263074126\n",
      "Epoch :  0074 cost =  0.262728558\n",
      "Epoch :  0075 cost =  0.262406570\n",
      "Epoch :  0076 cost =  0.261934653\n",
      "Epoch :  0077 cost =  0.261591504\n",
      "Epoch :  0078 cost =  0.261316425\n",
      "Epoch :  0079 cost =  0.260943477\n",
      "Epoch :  0080 cost =  0.260570128\n",
      "Epoch :  0081 cost =  0.260278772\n",
      "Epoch :  0082 cost =  0.259956985\n",
      "Epoch :  0083 cost =  0.259593663\n",
      "Epoch :  0084 cost =  0.259227109\n",
      "Epoch :  0085 cost =  0.258988267\n",
      "Epoch :  0086 cost =  0.258629446\n",
      "Epoch :  0087 cost =  0.258289120\n",
      "Epoch :  0088 cost =  0.258012037\n",
      "Epoch :  0089 cost =  0.257787256\n",
      "Epoch :  0090 cost =  0.257414633\n",
      "Epoch :  0091 cost =  0.257164812\n",
      "Epoch :  0092 cost =  0.256838956\n",
      "Epoch :  0093 cost =  0.256604521\n",
      "Epoch :  0094 cost =  0.256351291\n",
      "Epoch :  0095 cost =  0.256073835\n",
      "Epoch :  0096 cost =  0.255830467\n",
      "Epoch :  0097 cost =  0.255558315\n",
      "Epoch :  0098 cost =  0.255333037\n",
      "Epoch :  0099 cost =  0.255067199\n",
      "Epoch :  0100 cost =  0.254884693\n",
      "Epoch :  0101 cost =  0.254542917\n",
      "Epoch :  0102 cost =  0.254332905\n",
      "Epoch :  0103 cost =  0.254105299\n",
      "Epoch :  0104 cost =  0.253835375\n",
      "Epoch :  0105 cost =  0.253621477\n",
      "Epoch :  0106 cost =  0.253362153\n",
      "Epoch :  0107 cost =  0.253170324\n",
      "Epoch :  0108 cost =  0.252968605\n",
      "Epoch :  0109 cost =  0.252669505\n",
      "Epoch :  0110 cost =  0.252484754\n",
      "Epoch :  0111 cost =  0.252262447\n",
      "Epoch :  0112 cost =  0.252084170\n",
      "Epoch :  0113 cost =  0.251806357\n",
      "Epoch :  0114 cost =  0.251649660\n",
      "Epoch :  0115 cost =  0.251476469\n",
      "Epoch :  0116 cost =  0.251216658\n",
      "Epoch :  0117 cost =  0.251038554\n",
      "Epoch :  0118 cost =  0.250831479\n",
      "Epoch :  0119 cost =  0.250617863\n",
      "Epoch :  0120 cost =  0.250434239\n",
      "Epoch :  0121 cost =  0.250258348\n",
      "Epoch :  0122 cost =  0.250121493\n",
      "Epoch :  0123 cost =  0.249832670\n",
      "Epoch :  0124 cost =  0.249752939\n",
      "Epoch :  0125 cost =  0.249535334\n",
      "Epoch :  0126 cost =  0.249362500\n",
      "Epoch :  0127 cost =  0.249156020\n",
      "Epoch :  0128 cost =  0.248978090\n",
      "Epoch :  0129 cost =  0.248807988\n",
      "Epoch :  0130 cost =  0.248604695\n",
      "Epoch :  0131 cost =  0.248475328\n",
      "Epoch :  0132 cost =  0.248379386\n",
      "Epoch :  0133 cost =  0.248153390\n",
      "Epoch :  0134 cost =  0.247974264\n",
      "Epoch :  0135 cost =  0.247768438\n",
      "Epoch :  0136 cost =  0.247667457\n",
      "Epoch :  0137 cost =  0.247435124\n",
      "Epoch :  0138 cost =  0.247288008\n",
      "Epoch :  0139 cost =  0.247130399\n",
      "Epoch :  0140 cost =  0.247018309\n",
      "Epoch :  0141 cost =  0.246826309\n",
      "Epoch :  0142 cost =  0.246618840\n",
      "Epoch :  0143 cost =  0.246570937\n",
      "Epoch :  0144 cost =  0.246359415\n",
      "Epoch :  0145 cost =  0.246224683\n",
      "Epoch :  0146 cost =  0.246058074\n",
      "Epoch :  0147 cost =  0.245943381\n",
      "Epoch :  0148 cost =  0.245756049\n",
      "Epoch :  0149 cost =  0.245732308\n",
      "Epoch :  0150 cost =  0.245492751\n",
      "Epoch :  0151 cost =  0.245331222\n",
      "Epoch :  0152 cost =  0.245216905\n",
      "Epoch :  0153 cost =  0.245070308\n",
      "Epoch :  0154 cost =  0.244924820\n",
      "Epoch :  0155 cost =  0.244807541\n",
      "Epoch :  0156 cost =  0.244624384\n",
      "Epoch :  0157 cost =  0.244554665\n",
      "Epoch :  0158 cost =  0.244381811\n",
      "Epoch :  0159 cost =  0.244278036\n",
      "Epoch :  0160 cost =  0.244185011\n",
      "Epoch :  0161 cost =  0.244114988\n",
      "Epoch :  0162 cost =  0.243874722\n",
      "Epoch :  0163 cost =  0.243782941\n",
      "Epoch :  0164 cost =  0.243615056\n",
      "Epoch :  0165 cost =  0.243526794\n",
      "Epoch :  0166 cost =  0.243386147\n",
      "Epoch :  0167 cost =  0.243257207\n",
      "Epoch :  0168 cost =  0.243157396\n",
      "Epoch :  0169 cost =  0.243033117\n",
      "Epoch :  0170 cost =  0.242896469\n",
      "Epoch :  0171 cost =  0.242736595\n",
      "Epoch :  0172 cost =  0.242709087\n",
      "Epoch :  0173 cost =  0.242563841\n",
      "Epoch :  0174 cost =  0.242449442\n",
      "Epoch :  0175 cost =  0.242340595\n",
      "Epoch :  0176 cost =  0.242211169\n",
      "Epoch :  0177 cost =  0.242046542\n",
      "Epoch :  0178 cost =  0.241974089\n",
      "Epoch :  0179 cost =  0.241890573\n",
      "Epoch :  0180 cost =  0.241748246\n",
      "Epoch :  0181 cost =  0.241668168\n",
      "Epoch :  0182 cost =  0.241553295\n",
      "Epoch :  0183 cost =  0.241404186\n",
      "Epoch :  0184 cost =  0.241265453\n",
      "Epoch :  0185 cost =  0.241198737\n",
      "Epoch :  0186 cost =  0.241099516\n",
      "Epoch :  0187 cost =  0.240953039\n",
      "Epoch :  0188 cost =  0.240922711\n",
      "Epoch :  0189 cost =  0.240730255\n",
      "Epoch :  0190 cost =  0.240700779\n",
      "Epoch :  0191 cost =  0.240568907\n",
      "Epoch :  0192 cost =  0.240470325\n",
      "Epoch :  0193 cost =  0.240396306\n",
      "Epoch :  0194 cost =  0.240279126\n",
      "Epoch :  0195 cost =  0.240200516\n",
      "Epoch :  0196 cost =  0.240083303\n",
      "Epoch :  0197 cost =  0.239999325\n",
      "Epoch :  0198 cost =  0.239863144\n",
      "Epoch :  0199 cost =  0.239840925\n",
      "Epoch :  0200 cost =  0.239688156\n",
      "Epoch :  0201 cost =  0.239586593\n",
      "Epoch :  0202 cost =  0.239533227\n",
      "Epoch :  0203 cost =  0.239373897\n",
      "Epoch :  0204 cost =  0.239321310\n",
      "Epoch :  0205 cost =  0.239247731\n",
      "Epoch :  0206 cost =  0.239050839\n",
      "Epoch :  0207 cost =  0.239048546\n",
      "Epoch :  0208 cost =  0.238970957\n",
      "Epoch :  0209 cost =  0.238804407\n",
      "Epoch :  0210 cost =  0.238771937\n",
      "Epoch :  0211 cost =  0.238718075\n",
      "Epoch :  0212 cost =  0.238608902\n",
      "Epoch :  0213 cost =  0.238499755\n",
      "Epoch :  0214 cost =  0.238411250\n",
      "Epoch :  0215 cost =  0.238313514\n",
      "Epoch :  0216 cost =  0.238228775\n",
      "Epoch :  0217 cost =  0.238164999\n",
      "Epoch :  0218 cost =  0.238087920\n",
      "Epoch :  0219 cost =  0.237927686\n",
      "Epoch :  0220 cost =  0.237867639\n",
      "Epoch :  0221 cost =  0.237788840\n",
      "Epoch :  0222 cost =  0.237659435\n",
      "Epoch :  0223 cost =  0.237650755\n",
      "Epoch :  0224 cost =  0.237577259\n",
      "Epoch :  0225 cost =  0.237431005\n",
      "Epoch :  0226 cost =  0.237365983\n",
      "Epoch :  0227 cost =  0.237261455\n",
      "Epoch :  0228 cost =  0.237160682\n",
      "Epoch :  0229 cost =  0.237168445\n",
      "Epoch :  0230 cost =  0.237084143\n",
      "Epoch :  0231 cost =  0.236996265\n",
      "Epoch :  0232 cost =  0.236895223\n",
      "Epoch :  0233 cost =  0.236813018\n",
      "Epoch :  0234 cost =  0.236805026\n",
      "Epoch :  0235 cost =  0.236731617\n",
      "Epoch :  0236 cost =  0.236583689\n",
      "Epoch :  0237 cost =  0.236505584\n",
      "Epoch :  0238 cost =  0.236441904\n",
      "Epoch :  0239 cost =  0.236376391\n",
      "Epoch :  0240 cost =  0.236317042\n",
      "Epoch :  0241 cost =  0.236221950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0242 cost =  0.236141734\n",
      "Epoch :  0243 cost =  0.236093694\n",
      "Epoch :  0244 cost =  0.235963194\n",
      "Epoch :  0245 cost =  0.235932795\n",
      "Epoch :  0246 cost =  0.235897139\n",
      "Epoch :  0247 cost =  0.235723417\n",
      "Epoch :  0248 cost =  0.235739887\n",
      "Epoch :  0249 cost =  0.235632759\n",
      "Epoch :  0250 cost =  0.235566282\n",
      "Epoch :  0251 cost =  0.235451209\n",
      "Epoch :  0252 cost =  0.235456822\n",
      "Epoch :  0253 cost =  0.235388896\n",
      "Epoch :  0254 cost =  0.235281861\n",
      "Epoch :  0255 cost =  0.235251004\n",
      "Epoch :  0256 cost =  0.235171187\n",
      "Epoch :  0257 cost =  0.235086074\n",
      "Epoch :  0258 cost =  0.234998144\n",
      "Epoch :  0259 cost =  0.234965622\n",
      "Epoch :  0260 cost =  0.234898383\n",
      "Epoch :  0261 cost =  0.234807926\n",
      "Epoch :  0262 cost =  0.234740512\n",
      "Epoch :  0263 cost =  0.234677776\n",
      "Epoch :  0264 cost =  0.234623643\n",
      "Epoch :  0265 cost =  0.234542800\n",
      "Epoch :  0266 cost =  0.234471920\n",
      "Epoch :  0267 cost =  0.234392614\n",
      "Epoch :  0268 cost =  0.234394848\n",
      "Epoch :  0269 cost =  0.234236554\n",
      "Epoch :  0270 cost =  0.234269848\n",
      "Epoch :  0271 cost =  0.234178147\n",
      "Epoch :  0272 cost =  0.234136369\n",
      "Epoch :  0273 cost =  0.234059052\n",
      "Epoch :  0274 cost =  0.233952872\n",
      "Epoch :  0275 cost =  0.233928995\n",
      "Epoch :  0276 cost =  0.233883582\n",
      "Epoch :  0277 cost =  0.233825009\n",
      "Epoch :  0278 cost =  0.233747069\n",
      "Epoch :  0279 cost =  0.233692849\n",
      "Epoch :  0280 cost =  0.233644516\n",
      "Epoch :  0281 cost =  0.233554816\n",
      "Epoch :  0282 cost =  0.233517398\n",
      "Epoch :  0283 cost =  0.233450379\n",
      "Epoch :  0284 cost =  0.233368271\n",
      "Epoch :  0285 cost =  0.233346995\n",
      "Epoch :  0286 cost =  0.233264580\n",
      "Epoch :  0287 cost =  0.233183815\n",
      "Epoch :  0288 cost =  0.233129822\n",
      "Epoch :  0289 cost =  0.233079320\n",
      "Epoch :  0290 cost =  0.233006134\n",
      "Epoch :  0291 cost =  0.232970842\n",
      "Epoch :  0292 cost =  0.232879502\n",
      "Epoch :  0293 cost =  0.232844744\n",
      "Epoch :  0294 cost =  0.232823430\n",
      "Epoch :  0295 cost =  0.232736922\n",
      "Epoch :  0296 cost =  0.232697817\n",
      "Epoch :  0297 cost =  0.232615370\n",
      "Epoch :  0298 cost =  0.232584021\n",
      "Epoch :  0299 cost =  0.232499918\n",
      "Epoch :  0300 cost =  0.232483163\n",
      "Epoch :  0301 cost =  0.232447948\n",
      "Epoch :  0302 cost =  0.232323025\n",
      "Epoch :  0303 cost =  0.232318385\n",
      "Epoch :  0304 cost =  0.232252684\n",
      "Epoch :  0305 cost =  0.232193418\n",
      "Epoch :  0306 cost =  0.232169933\n",
      "Epoch :  0307 cost =  0.232111534\n",
      "Epoch :  0308 cost =  0.232029940\n",
      "Epoch :  0309 cost =  0.231945097\n",
      "Epoch :  0310 cost =  0.231862655\n",
      "Epoch :  0311 cost =  0.231801963\n",
      "Epoch :  0312 cost =  0.231860268\n",
      "Epoch :  0313 cost =  0.231762028\n",
      "Epoch :  0314 cost =  0.231703417\n",
      "Epoch :  0315 cost =  0.231664879\n",
      "Epoch :  0316 cost =  0.231668633\n",
      "Epoch :  0317 cost =  0.231568149\n",
      "Epoch :  0318 cost =  0.231495883\n",
      "Epoch :  0319 cost =  0.231466483\n",
      "Epoch :  0320 cost =  0.231415675\n",
      "Epoch :  0321 cost =  0.231364108\n",
      "Epoch :  0322 cost =  0.231314335\n",
      "Epoch :  0323 cost =  0.231274052\n",
      "Epoch :  0324 cost =  0.231190003\n",
      "Epoch :  0325 cost =  0.231186595\n",
      "Epoch :  0326 cost =  0.231076632\n",
      "Epoch :  0327 cost =  0.231059049\n",
      "Epoch :  0328 cost =  0.230986998\n",
      "Epoch :  0329 cost =  0.230900037\n",
      "Epoch :  0330 cost =  0.230934165\n",
      "Epoch :  0331 cost =  0.230847319\n",
      "Epoch :  0332 cost =  0.230782417\n",
      "Epoch :  0333 cost =  0.230776282\n",
      "Epoch :  0334 cost =  0.230671809\n",
      "Epoch :  0335 cost =  0.230651962\n",
      "Epoch :  0336 cost =  0.230628403\n",
      "Epoch :  0337 cost =  0.230588233\n",
      "Epoch :  0338 cost =  0.230513455\n",
      "Epoch :  0339 cost =  0.230490867\n",
      "Epoch :  0340 cost =  0.230452557\n",
      "Epoch :  0341 cost =  0.230322355\n",
      "Epoch :  0342 cost =  0.230371595\n",
      "Epoch :  0343 cost =  0.230338966\n",
      "Epoch :  0344 cost =  0.230264317\n",
      "Epoch :  0345 cost =  0.230176133\n",
      "Epoch :  0346 cost =  0.230180452\n",
      "Epoch :  0347 cost =  0.230131656\n",
      "Epoch :  0348 cost =  0.230044253\n",
      "Epoch :  0349 cost =  0.230016348\n",
      "Epoch :  0350 cost =  0.229981983\n",
      "Epoch :  0351 cost =  0.229892551\n",
      "Epoch :  0352 cost =  0.229939507\n",
      "Epoch :  0353 cost =  0.229858989\n",
      "Epoch :  0354 cost =  0.229835854\n",
      "Epoch :  0355 cost =  0.229775458\n",
      "Epoch :  0356 cost =  0.229697109\n",
      "Epoch :  0357 cost =  0.229648942\n",
      "Epoch :  0358 cost =  0.229608852\n",
      "Epoch :  0359 cost =  0.229596877\n",
      "Epoch :  0360 cost =  0.229496436\n",
      "Epoch :  0361 cost =  0.229487695\n",
      "Epoch :  0362 cost =  0.229456838\n",
      "Epoch :  0363 cost =  0.229387875\n",
      "Epoch :  0364 cost =  0.229393871\n",
      "Epoch :  0365 cost =  0.229272508\n",
      "Epoch :  0366 cost =  0.229313777\n",
      "Epoch :  0367 cost =  0.229278829\n",
      "Epoch :  0368 cost =  0.229188093\n",
      "Epoch :  0369 cost =  0.229164652\n",
      "Epoch :  0370 cost =  0.229089722\n",
      "Epoch :  0371 cost =  0.229116592\n",
      "Epoch :  0372 cost =  0.229008884\n",
      "Epoch :  0373 cost =  0.228986933\n",
      "Epoch :  0374 cost =  0.228968516\n",
      "Epoch :  0375 cost =  0.228924831\n",
      "Epoch :  0376 cost =  0.228877637\n",
      "Epoch :  0377 cost =  0.228831097\n",
      "Epoch :  0378 cost =  0.228800690\n",
      "Epoch :  0379 cost =  0.228754366\n",
      "Epoch :  0380 cost =  0.228724064\n",
      "Epoch :  0381 cost =  0.228706386\n",
      "Epoch :  0382 cost =  0.228626152\n",
      "Epoch :  0383 cost =  0.228618568\n",
      "Epoch :  0384 cost =  0.228583199\n",
      "Epoch :  0385 cost =  0.228535544\n",
      "Epoch :  0386 cost =  0.228450022\n",
      "Epoch :  0387 cost =  0.228449095\n",
      "Epoch :  0388 cost =  0.228371946\n",
      "Epoch :  0389 cost =  0.228375475\n",
      "Epoch :  0390 cost =  0.228299847\n",
      "Epoch :  0391 cost =  0.228216972\n",
      "Epoch :  0392 cost =  0.228280853\n",
      "Epoch :  0393 cost =  0.228211483\n",
      "Epoch :  0394 cost =  0.228199321\n",
      "Epoch :  0395 cost =  0.228116439\n",
      "Epoch :  0396 cost =  0.228061684\n",
      "Epoch :  0397 cost =  0.228040141\n",
      "Epoch :  0398 cost =  0.228021393\n",
      "Epoch :  0399 cost =  0.227968356\n",
      "Epoch :  0400 cost =  0.227971771\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        #feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch #뭉치갯수로 나누기\n",
    "        \n",
    "    print('Epoch : ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9287\n",
      "Label: [0]\n",
      "Prediction: [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "feed_dict = {X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}\n",
    "print(\"Accuracy : \", accuracy.eval(session=sess, feed_dict=feed_dict))\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print('Label:', sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print('Prediction:', sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r+1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
